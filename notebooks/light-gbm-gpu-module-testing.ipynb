{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Light GBM GPU Module \n\n    * This simple notebook is to install Light GBM with GPU. Unfortunately, using kaggle notebooks you must install light gbm each time you want to use light gbm in the notebooks themselves. Furthermore, in the specific competition (Crypto), you are not allowed to use the internet in main notebook for submission. So, with this notebook, I am hoping to downlaod light gbm and make it available to my main notebook in a .tar file. This may be a grey area for whether this is acceptable or not, but more than likely the usbmission will fail if it is not acceptable since any supporting notebooks will require the 'no-internet' option. \n    \n    Either way, it is an intereting idea to try and gives others the chance to look at how to use GBM with GPU. ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-06T05:33:26.209730Z","iopub.execute_input":"2021-12-06T05:33:26.210057Z","iopub.status.idle":"2021-12-06T05:33:26.244586Z","shell.execute_reply.started":"2021-12-06T05:33:26.209973Z","shell.execute_reply":"2021-12-06T05:33:26.243905Z"}}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt-get update\n!apt-get install --no-install-recommends nvidia-375\n!apt-get install --no-install-recommends nvidia-opencl-icd-375 nvidia-opencl-dev opencl-headers","metadata":{"execution":{"iopub.status.busy":"2021-12-06T05:34:39.690876Z","iopub.execute_input":"2021-12-06T05:34:39.691129Z","iopub.status.idle":"2021-12-06T05:34:44.874458Z","shell.execute_reply.started":"2021-12-06T05:34:39.691101Z","shell.execute_reply":"2021-12-06T05:34:44.873810Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!apt-get install --no-install-recommends git cmake build-essential libboost-dev libboost-system-dev libboost-filesystem-dev","metadata":{"execution":{"iopub.status.busy":"2021-12-06T05:34:53.449160Z","iopub.execute_input":"2021-12-06T05:34:53.449450Z","iopub.status.idle":"2021-12-06T05:34:55.205639Z","shell.execute_reply.started":"2021-12-06T05:34:53.449420Z","shell.execute_reply":"2021-12-06T05:34:55.204372Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /mnt/workspace\n!chown $(whoami):$(whoami) /mnt/workspace\n!cd /mnt/workspace","metadata":{"execution":{"iopub.status.busy":"2021-12-06T05:35:06.883549Z","iopub.execute_input":"2021-12-06T05:35:06.883813Z","iopub.status.idle":"2021-12-06T05:35:07.717124Z","shell.execute_reply.started":"2021-12-06T05:35:06.883788Z","shell.execute_reply":"2021-12-06T05:35:07.716075Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!git clone --recursive https://github.com/microsoft/LightGBM\n!cd LightGBM\n!mkdir build\n!cd build\n!cmake -DUSE_GPU=1 ..\n# if you have installed NVIDIA CUDA to a customized location, you should specify paths to OpenCL headers and library like the following:\n# cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n!make -j$(nproc)\n!cd ..","metadata":{"execution":{"iopub.status.busy":"2021-12-06T05:35:18.033330Z","iopub.execute_input":"2021-12-06T05:35:18.033632Z","iopub.status.idle":"2021-12-06T05:35:39.832894Z","shell.execute_reply.started":"2021-12-06T05:35:18.033600Z","shell.execute_reply":"2021-12-06T05:35:39.832078Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import tarfile\n\nwith tarfile.open('./LightGBM.tar', 'w') as tar:\n    tar.add('LightGBM', arcname='LightGBM')\n\n!du -sh ./*","metadata":{"execution":{"iopub.status.busy":"2021-12-06T05:37:14.964925Z","iopub.execute_input":"2021-12-06T05:37:14.965209Z","iopub.status.idle":"2021-12-06T05:37:16.599880Z","shell.execute_reply.started":"2021-12-06T05:37:14.965181Z","shell.execute_reply":"2021-12-06T05:37:16.599146Z"},"trusted":true},"execution_count":9,"outputs":[]}]}